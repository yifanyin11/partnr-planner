llm:
  _target_    : habitat_llm.llm.OpenAIChat
  _partial_   : True

verbose       : True

# The system message helps set the behavior of the assistant.
# "You are a helpful assistant." or "You're an expert in deep learning."
# system_message       : 'You are a helpful assistant.'
system_message       : 'You are an expert at task planning.'

# System, User, Assistant and end of turn tags
system_tag : ""
user_tag : ""
assistant_tag : ""
eot_tag : ""

# Decide whether to keep history
keep_message_history   : False

generation_params:
  # gpt-3.5-turbo, gpt-3.5-turbo-16k
  model        : gpt-4o

  # The messages between the user and the bot
  #messages        : ''

  # The maximum number of tokens to generate in the completion.
  max_tokens    : 250

  # Sampling temperature between 0 and 2. Higher values will make the output more random,
  # while lower values like 0.2 will make it more focused and deterministic.
  temperature   : 0

  # An alternative to temperature, nucleus sampling. The model considers the results
  # of the toklen with top_p probability mass. So 0.1 means only the tokens comprising
  # the top 10% probability mass are considered.
  top_p         : 1

  # Whether to stream back partial progress
  stream        : False

  # up to 4 sequences that stop the generation
  stop          : ''

  # Dictionary that can modify the likelihood of specified tokens appearing in the completion.
  # logit_bias: {}

  # Other params
  frequency_penalty : 0
  presence_penalty  : 0
  request_timeout   : 20
